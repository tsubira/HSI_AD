{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HSI_utils import *\n",
    "import torch\n",
    "from vit import *\n",
    "from mae import *\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "PATCH_SIZE = 10\n",
    "EPOCHS = 4000\n",
    "loss = 'mse'\n",
    "# loss = 'weighted_l2'\n",
    "# loss = 'mae'\n",
    "\n",
    "# Optional PCA layers reduction\n",
    "PCA = 0\n",
    "dim_enc = 8\n",
    "dim_dec = 8\n",
    "\n",
    "# Use \"TRAIN\" to train a model. Otherwise, the notebook will only evaluate.\n",
    "# Use \"LOAD\" to load a presaved model. Otherwise, the notebook will use a newly createdm model.\n",
    "TRAIN = True\n",
    "LOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = os.path.join(\"data\")\n",
    "df_files = create_df_from_files_in_path(ruta, verbose = True)\n",
    "\n",
    "# List with the index of the images to use in the training. \n",
    "# Every image will be trained on a separated model.\n",
    "list_imgs = [3]\n",
    "\n",
    "# for id_img in df_files.index:\n",
    "for id_img in list_imgs:\n",
    "  name = df_files.Filename[id_img]\n",
    "  print(f'>> Processing image {name}...')\n",
    "\n",
    "  # Prepare dataset (HSI)\n",
    "  layers = df_files.Layers[id_img]\n",
    "  height = df_files.Height[id_img]\n",
    "  width = df_files.Width[id_img]\n",
    "  x_n = torch.zeros(1, layers, height, width)\n",
    "\n",
    "  anomaly_map, hs_image = load_HSI_from_idx(id_img, df_files, verbose = True)\n",
    "  hs_image = norm_img(hs_image)\n",
    "  if PCA > 0:\n",
    "    hs_image = reduce_HSI_dim_with_PCA(hs_image, PCA)\n",
    "    hs_image = norm_img(hs_image)\n",
    "\n",
    "  print_RGB_HSI(hs_image, img_name = name)\n",
    "  print(f'Image under test with dimmensions {np.shape(hs_image)}')\n",
    "\n",
    "  x_i = torch.from_numpy(np.float32(hs_image.copy()))\n",
    "  x_i = torch.permute(x_i, (2, 0, 1))\n",
    "  x_n[0,:,:] = x_i\n",
    "\n",
    "  if TRAIN == True or LOAD == True:\n",
    "    # Create the ViT encoder\n",
    "    v = ViT(\n",
    "        image_size = height,\n",
    "        patch_size = PATCH_SIZE,\n",
    "        channels = layers,\n",
    "        num_classes = 1,\n",
    "        dim = dim_enc,\n",
    "        depth = 4,\n",
    "        heads = 8,\n",
    "        mlp_dim = 32,\n",
    "        emb_dropout = 0,\n",
    "        pool = 'mean',\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    # Create the Masked Autoencoder model\n",
    "    mae = MAE(\n",
    "        encoder = v,\n",
    "        masking_ratio = 0.7,   \n",
    "        decoder_dim = dim_dec,     \n",
    "        decoder_depth = 4,       # anywhere from 1 to 8\n",
    "        decoder_heads = 8,\n",
    "        decoder_dim_head = 32,\n",
    "        lr = 5e-4,\n",
    "        verbose = 1\n",
    "    )\n",
    "    print(f'>> Model for {name} created.')\n",
    "\n",
    "  if LOAD == True:\n",
    "    # load previous weights for the model\n",
    "    mae.load_state_dict(torch.load(name + '_TEST.pth'))\n",
    "    df_history = pd.read_csv('./training_losses_TEST_' + name + '.csv')\n",
    "    mae.loss_history = df_history.MSE.values.tolist()\n",
    "\n",
    "  if TRAIN == True:\n",
    "    # train the model\n",
    "    mae.training_loop(x_n, EPOCHS, autosave = 0, loss_fcn = loss)\n",
    "\n",
    "    # save the training history\n",
    "    history = (mae.loss_history)\n",
    "    df_history = pd.DataFrame(history, columns=['MSE'])\n",
    "    df_history.to_csv('./training_losses_TEST_' + name + '.csv')\n",
    "\n",
    "    # save your improved vision transformer\n",
    "    torch.save(mae.state_dict(), './' + name + '_TEST.pth')\n",
    "\n",
    "    # Plot the training history\n",
    "    history = (mae.loss_history)\n",
    "    plt.plot(history)\n",
    "    plt.title(name + ' TRAINING LOSS HISTORY')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('RL')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar functions\n",
    "def reconstruct_patch(patch_vector):\n",
    "    rec_patch = torch.zeros((PATCH_SIZE, PATCH_SIZE, layers))\n",
    "    for patch_pixel in range(PATCH_SIZE**2):\n",
    "        id_pixel = 0\n",
    "        for row in range(PATCH_SIZE):\n",
    "            for column in range(PATCH_SIZE):\n",
    "                rec_patch[row, column, :] = patch_vector[id_pixel*layers:(id_pixel+1)*layers]\n",
    "                id_pixel += 1\n",
    "    return rec_patch\n",
    "\n",
    "def iterative_gaussian_blur(image, n_iters = 5, var = 1):\n",
    "  for i in range(n_iters):\n",
    "    image = cv2.GaussianBlur(image, (3,3), var)\n",
    "  return (image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = os.path.join(\"data\")\n",
    "df_files = create_df_from_files_in_path(ruta, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruction of the HSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loop\n",
    "\n",
    "list_names_imgs = []\n",
    "list_original_imgs = []\n",
    "list_reconstructed_imgs = [] \n",
    "list_anomaly_maps = []\n",
    "\n",
    "list_imgs = [3]\n",
    "\n",
    "# for id_img in df_files.index:\n",
    "for id_img in list_imgs:\n",
    "  name = df_files.Filename[id_img]\n",
    "  print(f'>> Processing image {name}...')\n",
    "\n",
    "  # Prepare dataset (HSI)\n",
    "  layers = df_files.Layers[id_img]\n",
    "  height = df_files.Height[id_img]\n",
    "  width = df_files.Width[id_img]\n",
    "  x_n = torch.zeros(1, layers, height, width)\n",
    "  anomaly_map, hs_image = load_HSI_from_idx(id_img, df_files, verbose = True)\n",
    "  hs_image = norm_img(hs_image)\n",
    "  if PCA > 0:\n",
    "    hs_image = reduce_HSI_dim_with_PCA(hs_image, PCA)\n",
    "    hs_image = norm_img(hs_image)\n",
    "  x_i = torch.from_numpy(np.float32(hs_image.copy()))\n",
    "  x_i = torch.permute(x_i, (2, 0, 1))\n",
    "  x_n[0,:,:] = x_i\n",
    "\n",
    "  # Create the ViT encoder\n",
    "  v = ViT(\n",
    "      image_size = height,\n",
    "      patch_size = PATCH_SIZE,\n",
    "      channels = layers,\n",
    "      num_classes = 1,\n",
    "      dim = dim_enc,\n",
    "      depth = 4,\n",
    "      heads = 8,\n",
    "      mlp_dim = 32,\n",
    "      emb_dropout = 0,\n",
    "      pool = 'mean',\n",
    "      verbose = 1\n",
    "  )\n",
    "\n",
    "  # Create the Masked Autoencoder model\n",
    "  mae = MAE(\n",
    "      encoder = v,\n",
    "      masking_ratio = 0.7,   \n",
    "      decoder_dim = dim_dec,     \n",
    "      decoder_depth = 4,       # anywhere from 1 to 8\n",
    "      decoder_heads = 8,\n",
    "      decoder_dim_head = 32,\n",
    "      lr = 5e-4,\n",
    "      verbose = 1\n",
    "  )\n",
    "\n",
    "  print(f'>> Model for {name} created.')\n",
    "\n",
    "  # Load previous weights for the model\n",
    "  mae.load_state_dict(torch.load(name + '_TEST.pth'))\n",
    "  df_history = pd.read_csv('./training_losses_TEST_' + name + '.csv')\n",
    "  mae.loss_history = df_history.MSE.values.tolist()\n",
    "\n",
    "  # Reconstruct the image\n",
    "  reconstructed_img = mae.reconstruct_image(x_n)\n",
    "\n",
    "  # Reorganization of the reconstructed image\n",
    "  x_hat = torch.zeros((height, width, layers))\n",
    "  rec_img = reconstructed_img[0,:]\n",
    "  id_patch = 0\n",
    "  for row in range(int(height/PATCH_SIZE)):\n",
    "      for column in range(int(width/PATCH_SIZE)):\n",
    "          patch_vector = rec_img[id_patch, :]\n",
    "          patch = reconstruct_patch(patch_vector)\n",
    "          x_hat[row*PATCH_SIZE:(row+1)*PATCH_SIZE, column*PATCH_SIZE:(column+1)*PATCH_SIZE, :] = patch\n",
    "          id_patch += 1\n",
    "  img = x_hat.detach().numpy()\n",
    "  img = norm_img(img)\n",
    "\n",
    "  print(f'Image {name} reconstructed. Storing the data...')\n",
    "\n",
    "  # Store the images\n",
    "  list_names_imgs.append(name)\n",
    "  list_original_imgs.append(hs_image)\n",
    "  list_anomaly_maps.append(anomaly_map)\n",
    "  list_reconstructed_imgs.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomaly Detection and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_MAP = 'mse'\n",
    "# ERROR_MAP = 'mae'\n",
    "# ERROR_MAP = 'SAD'\n",
    "smooth_iters = 2\n",
    "\n",
    "# Test loop\n",
    "for idx, img in enumerate(list_reconstructed_imgs):\n",
    "  name = list_names_imgs[idx]\n",
    "  hs_image = list_original_imgs[idx]\n",
    "  anomaly_map = list_anomaly_maps[idx]\n",
    "\n",
    "  print_RGB_HSI(hs_image, img_name = name)\n",
    "  print_RGB_HSI(img, img_name = 'RECONSTRUCTED ' + name)\n",
    "\n",
    "  if ERROR_MAP == 'mse':\n",
    "    error_map = np.mean(np.abs(((hs_image - img)**2)), 2)\n",
    "  elif ERROR_MAP == 'mae':\n",
    "    error_map = np.mean(np.abs(((hs_image - img))), 2)\n",
    "  elif ERROR_MAP == 'SAD':\n",
    "    error_map = SAD(hs_image, img)\n",
    "\n",
    "  # Plot the smoothed error and the results from the 2D-CFAR\n",
    "  fig, ax = plt.subplots(2, 2, figsize=(9,9))\n",
    "\n",
    "  plt.subplot(221)\n",
    "  plt.imshow(anomaly_map, cmap=plt.cm.gray)\n",
    "  plt.title(f'Reference Anomaly map')\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.subplot(222)\n",
    "  plt.imshow(error_map, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "  plt.title(f'Error map')\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Gaussian blur\n",
    "  error_map_gauss = iterative_gaussian_blur(error_map, n_iters = smooth_iters, var = 0.8)\n",
    "  error_map_gauss = norm_img(error_map_gauss)\n",
    "\n",
    "  plt.subplot(223)\n",
    "  plt.imshow(error_map_gauss, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "  plt.title(f'Smoothed Error map')\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Detection threshold: CFAR\n",
    "  anomaly_detection_map = CFAR_2D(error_map_gauss, thr_type = 'higher', filter_dims = 5, gap_pixels = 1, thr_factor = 1.75)\n",
    "  anomaly_detection_map = norm_img(anomaly_detection_map)\n",
    "\n",
    "  plt.subplot(224)\n",
    "  plt.imshow(anomaly_detection_map, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "  plt.title(f'Anomaly Detection map')\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Calculate pd and pfa by thresholding the CFAR\n",
    "  AD_CFAR = filter_image_over_threshold(anomaly_detection_map, 0)\n",
    "  pd_CFAR = compute_pd(anomaly_map, AD_CFAR)\n",
    "  pfa_CFAR = compute_pfa(anomaly_map, AD_CFAR)\n",
    "\n",
    "  # Calculate and plot ROC\n",
    "  pd_list_error, pl_list_error, pfa_list_error = compute_ROC(anomaly_map.copy(), error_map_gauss.copy())\n",
    "  AUC = metrics.auc(pfa_list_error, pd_list_error)\n",
    "\n",
    "  fig = plt.figure(figsize=(7,4))\n",
    "  # plt.semilogx(pfa_list_error, pl_list_error, color='k', label = 'ROC localization')\n",
    "  plt.semilogx(pfa_list_error, pd_list_error, color='r', label = 'ROC pd/pfa')\n",
    "  plt.scatter(pfa_CFAR, pd_CFAR, color = 'r', label = '2D-CFAR threshold')\n",
    "  plt.ylabel('Probability of Detection')\n",
    "  plt.xlabel('Probability of False Alarm')\n",
    "  plt.title(f'ROC curve with AUC = {AUC:.4f}')\n",
    "  plt.grid()\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91083532a104cf18c834774762e3461915a48c8c933286d8c0b2f27055b57851"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
